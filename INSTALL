
Installation
------------

This directory contains the binaries for commandline tools to manage the cloud-based rumen
metagenomics pipeline.  This file describes the installation of the software.

DEPENDENCIES
------------

You need java and groovy, I'm assuming you have that setup up the path variables such
that % java  and % groovysh work.  It also assumes that you have a hadoop cluster and
the hadoop executable should be setup in the path as well.  You can still use this without
a cluster, by default the hadoop commandline will run in single-node mode.


To BUILD from Source:
---------------------

see BUILD_INSTRUCTIONS in the source for more details.  At the end of the process
the binary tgz file will be in

   ./meta/target/meta-<version>-bin.tar.gz

once you have the binary package, follow the instructions below to install.

To INSTALL
----------

Step 0: make sure java and groovy are working
   % java -version
   java version "1.6.0_17"

   % groovysh -version
   Groovy Shell 1.6.2

Step 1: untar the tar file in some location where you want to install
   % tar -zxvf meta-0.1-SNAPSHOT-bin.tar.gz -C /usr/local/

   this installs the directory that includes this INSTALL file


Step 2: set your path

   add the following to your .profile or type

   # meta
   export META_HOME=${HOME}/local/meta
   export PATH=${PATH}:${META_HOME}/bin
   export MANPATH=${MANPATH}:${META_HOME}/man

Step 3: configure the groovy load path

   In your .profile (or .bash_profile etc) add the following:
   export GROOVY_CONF=~/.groovy/groovy-starter.conf

   now, create the above file with the following contents:

# load required libraries
load !{groovy.home}/lib/*.jar
# load user specific libraries
load !{user.home}/.groovy/lib/*.jar
# tools.jar for ant tasks
load ${tools.jar}
load !{meta.home}/lib/*.jar

In order to define meta.home system variable add the following environment variable to
your setup:

% export JAVA_OPTS=" -Dmeta.home=${META_HOME}


To test it out try
   % meta -help

Step 3: finally, set the hadoop classpath so that it can find the configuration
        directory

% export HADOOP_CLASSPATH=/usr/local/meta/conf

the conf directory has application-level parameters that are site-specific, things like
memory size, number of processes to split, etc.

you are all set to go.

DEFAULTS
--------

The commandline tool reads a properties file from your home directory, ~/.meta-prefs and
can use those values as defaults to decrease the number of parameters that are needed.

see ./meta/etc/dot.meta-prefs for the list of properties and template that you can use.
copy this file to ~/.meta-prefs


USAGE
------

% meta --help

